{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33cdbb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6430685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ModelCheckpoint, \n",
    "    EarlyStopping, \n",
    "    ReduceLROnPlateau,\n",
    "    TensorBoard\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05614484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Dataset Paths\n",
    "    DATA_DIR = \"./dataset\"\n",
    "    CLASSES = [\"anorganik\", \"organik\"]  # Sesuai struktur folder\n",
    "    \n",
    "    # Model Parameters\n",
    "    IMG_SIZE = 300  # Lebih besar untuk akurasi tinggi\n",
    "    BATCH_SIZE = 32\n",
    "    EPOCHS = 100\n",
    "    INIT_LR = 1e-4\n",
    "    \n",
    "    # Augmentation\n",
    "    ROTATION_RANGE = 40\n",
    "    ZOOM_RANGE = 0.3\n",
    "    WIDTH_SHIFT_RANGE = 0.2\n",
    "    \n",
    "    # Output\n",
    "    MODEL_DIR = \"./models\"\n",
    "    LOG_DIR = \"./logs\"\n",
    "\n",
    "config = Config()\n",
    "os.makedirs(config.MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(config.LOG_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a61b6f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18052 images belonging to 2 classes.\n",
      "Found 4512 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights (untuk handle imbalance)\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.arange(len(config.CLASSES)),\n",
    "    y=np.concatenate([np.full(len(os.listdir(f\"{config.DATA_DIR}/{cls}\")), i) \n",
    "               for i, cls in enumerate(config.CLASSES)])\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Advanced Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=config.ROTATION_RANGE,\n",
    "    zoom_range=config.ZOOM_RANGE,\n",
    "    width_shift_range=config.WIDTH_SHIFT_RANGE,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    validation_split=0.2,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Train Generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    config.DATA_DIR,\n",
    "    target_size=(config.IMG_SIZE, config.IMG_SIZE),\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training',\n",
    "    classes=config.CLASSES,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Validation Generator (minimal augmentation)\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    config.DATA_DIR,\n",
    "    target_size=(config.IMG_SIZE, config.IMG_SIZE),\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation',\n",
    "    classes=config.CLASSES,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9e10ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18052 images belonging to 2 classes.\n",
      "Found 4512 images belonging to 2 classes.\n",
      "\n",
      "ðŸ” Dataset Summary:\n",
      "Training samples: 18052\n",
      "Validation samples: 4512\n",
      "Class indices: {'anorganik': 0, 'organik': 1}\n"
     ]
    }
   ],
   "source": [
    "def create_generators():\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        config.DATA_DIR,\n",
    "        target_size=(config.IMG_SIZE, config.IMG_SIZE),\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        subset='training',\n",
    "        classes=config.CLASSES\n",
    "    )\n",
    "\n",
    "    val_generator = train_datagen.flow_from_directory(\n",
    "        config.DATA_DIR,\n",
    "        target_size=(config.IMG_SIZE, config.IMG_SIZE),\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        subset='validation',\n",
    "        classes=config.CLASSES\n",
    "    )\n",
    "\n",
    "    print(f\"\\nðŸ” Dataset Summary:\")\n",
    "    print(f\"Training samples: {train_generator.samples}\")\n",
    "    print(f\"Validation samples: {val_generator.samples}\")\n",
    "    print(f\"Class indices: {train_generator.class_indices}\")\n",
    "\n",
    "    return train_generator, val_generator\n",
    "\n",
    "train_gen, val_gen = create_generators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "530194f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
      "43941136/43941136 [==============================] - 37s 1us/step\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras.optimizers' has no attribute 'AdamW'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 42\u001b[0m\n\u001b[0;32m     30\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     31\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     32\u001b[0m         loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m         ]\n\u001b[0;32m     38\u001b[0m     )\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m---> 42\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_advanced_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "Cell \u001b[1;32mIn[9], line 25\u001b[0m, in \u001b[0;36mbuild_advanced_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSequential([\n\u001b[0;32m     13\u001b[0m     base_model,\n\u001b[0;32m     14\u001b[0m     layers\u001b[38;5;241m.\u001b[39mGlobalAveragePooling2D(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m ])\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Custom optimizer dengan weight decay\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdamW\u001b[49m(\n\u001b[0;32m     26\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mINIT_LR,\n\u001b[0;32m     27\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     31\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m     32\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     ]\n\u001b[0;32m     38\u001b[0m )\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.api._v2.keras.optimizers' has no attribute 'AdamW'"
     ]
    }
   ],
   "source": [
    "def build_advanced_model():\n",
    "    # Gunakan EfficientNet dengan input size lebih besar\n",
    "    base_model = EfficientNetB3(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(config.IMG_SIZE, config.IMG_SIZE, 3)\n",
    "    )\n",
    "    \n",
    "    # Freeze base model awal\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(512, activation='swish', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(256, activation='swish', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    # Custom optimizer dengan weight decay\n",
    "    optimizer = tf.keras.optimizers.AdamW(\n",
    "        learning_rate=config.INIT_LR,\n",
    "        weight_decay=1e-5\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.Precision(name='precision'),\n",
    "            tf.keras.metrics.Recall(name='recall')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_advanced_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461e55ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progressive Unfreezing Callback\n",
    "class UnfreezeCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch == 20:  # Unfreeze setelah 20 epoch\n",
    "            self.model.layers[0].trainable = True\n",
    "            for layer in self.model.layers[0].layers[:-20]:  # Hanya unfreeze layer atas\n",
    "                layer.trainable = False\n",
    "            self.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5))\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath=os.path.join(config.MODEL_DIR, 'best_model.h5'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max'\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7\n",
    "    ),\n",
    "    TensorBoard(\n",
    "        log_dir=config.LOG_DIR\n",
    "    ),\n",
    "    UnfreezeCallback()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697e7ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=config.EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weights,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0430b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training History\n",
    "def plot_history(history):\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    \n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train')\n",
    "    plt.plot(history.history['val_loss'], label='Validation')\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(config.LOG_DIR, 'training_history.png'))\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)\n",
    "\n",
    "# Classification Report\n",
    "val_generator.reset()\n",
    "y_pred = model.predict(val_generator)\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "y_true = val_generator.classes\n",
    "\n",
    "print(\"\\nðŸ“Š Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=config.CLASSES))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=config.CLASSES, \n",
    "            yticklabels=config.CLASSES)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig(os.path.join(config.LOG_DIR, 'confusion_matrix.png'))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ae0f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(config.MODEL_DIR, 'final_model.h5'))\n",
    "print(\"âœ… Training completed! Model saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
