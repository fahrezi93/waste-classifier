{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c17623e3",
   "metadata": {},
   "source": [
    "# ðŸš€ Training Model Klasifikasi Sampah"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a780bd60",
   "metadata": {},
   "source": [
    "Impor Library dan Konfigurasi Utama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c6ffd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.10.0\n",
      "GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import EfficientNetB4, MobileNetV2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "# --- Konfigurasi Utama ---\n",
    "class Config:\n",
    "    DATASET_DIR = \"./dataset\"\n",
    "    IMG_SIZE = 224\n",
    "    BATCH_SIZE = 16\n",
    "    USE_EFFICIENTNET = True \n",
    "    DROPOUT_RATE = 0.4\n",
    "    INITIAL_EPOCHS = 30\n",
    "    FINE_TUNE_EPOCHS = 50\n",
    "    INITIAL_LR = 1e-3\n",
    "    VALIDATION_SPLIT = 0.2\n",
    "    SAVE_DIR = \"./models_output\"\n",
    "\n",
    "config = Config()\n",
    "os.makedirs(config.SAVE_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25754628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menghapus direktori lama: .\\dataset_organized\n",
      "Membuat struktur direktori baru di: .\\dataset_organized\n",
      "âœ… Dataset berhasil diorganisir.\n"
     ]
    }
   ],
   "source": [
    "def prepare_dataset():\n",
    "    source_dir = config.DATASET_DIR\n",
    "    organized_dir = os.path.join(os.path.dirname(source_dir), \"dataset_organized\")\n",
    "\n",
    "    if os.path.exists(organized_dir):\n",
    "        print(f\"Menghapus direktori lama: {organized_dir}\")\n",
    "        shutil.rmtree(organized_dir)\n",
    "\n",
    "    print(f\"Membuat struktur direktori baru di: {organized_dir}\")\n",
    "    \n",
    "    train_dir = os.path.join(organized_dir, 'train')\n",
    "    val_dir = os.path.join(organized_dir, 'validation')\n",
    "    \n",
    "    classes = [d for d in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, d))]\n",
    "    \n",
    "    for cls in classes:\n",
    "        os.makedirs(os.path.join(train_dir, cls), exist_ok=True)\n",
    "        os.makedirs(os.path.join(val_dir, cls), exist_ok=True)\n",
    "\n",
    "    for cls in classes:\n",
    "        files = [f for f in os.listdir(os.path.join(source_dir, cls)) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        np.random.shuffle(files)\n",
    "        \n",
    "        split_index = int(len(files) * (1 - config.VALIDATION_SPLIT))\n",
    "        train_files = files[:split_index]\n",
    "        val_files = files[split_index:]\n",
    "\n",
    "        for f in train_files:\n",
    "            shutil.copy(os.path.join(source_dir, cls, f), os.path.join(train_dir, cls, f))\n",
    "        for f in val_files:\n",
    "            shutil.copy(os.path.join(source_dir, cls, f), os.path.join(val_dir, cls, f))\n",
    "            \n",
    "    print(\"âœ… Dataset berhasil diorganisir.\")\n",
    "    return organized_dir\n",
    "\n",
    "# Jalankan fungsi persiapan dataset\n",
    "organized_data_dir = prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e65b132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18051 images belonging to 2 classes.\n",
      "Found 4513 images belonging to 2 classes.\n",
      "Kelas ditemukan: ['anorganik', 'organik']\n"
     ]
    }
   ],
   "source": [
    "def create_data_generators(data_dir):\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        os.path.join(data_dir, 'train'),\n",
    "        target_size=(config.IMG_SIZE, config.IMG_SIZE),\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "        os.path.join(data_dir, 'validation'),\n",
    "        target_size=(config.IMG_SIZE, config.IMG_SIZE),\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_generator, validation_generator\n",
    "\n",
    "# Jalankan fungsi untuk membuat generator\n",
    "train_gen, val_gen = create_data_generators(organized_data_dir)\n",
    "print(f\"Kelas ditemukan: {list(train_gen.class_indices.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e18d035c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Menggunakan arsitektur EfficientNetB4.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb4 (Functional)  (None, 7, 7, 1792)       17673823  \n",
      "                                                                 \n",
      " global_average_pooling2d_2   (None, 1792)             0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1792)             7168      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               459008    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18,140,256\n",
      "Trainable params: 462,849\n",
      "Non-trainable params: 17,677,407\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(num_classes=1):\n",
    "    if config.USE_EFFICIENTNET:\n",
    "        base_model = EfficientNetB4(weights='imagenet', include_top=False, input_shape=(config.IMG_SIZE, config.IMG_SIZE, 3))\n",
    "        print(\"ðŸš€ Menggunakan arsitektur EfficientNetB4.\")\n",
    "    else:\n",
    "        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(config.IMG_SIZE, config.IMG_SIZE, 3))\n",
    "        print(\"âš¡ Menggunakan arsitektur MobileNetV2.\")\n",
    "\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(config.DROPOUT_RATE),\n",
    "        layers.Dense(num_classes, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Bangun modelnya\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "895e4b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TAHAP 1: Melatih Head Model (Feature Extraction) ---\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential_2/efficientnetb4/block4e_expand_bn/FusedBatchNormV3' defined at (most recent call last):\n    File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 397, in dispatch_shell\n      await result\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 368, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 752, in execute_request\n      reply_content = await reply_content\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 455, in do_execute\n      res = shell.run_cell(\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 577, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_20580\\1583126195.py\", line 20, in <module>\n      history = model.fit(\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 850, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 660, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 634, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'sequential_2/efficientnetb4/block4e_expand_bn/FusedBatchNormV3'\nOOM when allocating tensor with shape[32,672,14,14] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential_2/efficientnetb4/block4e_expand_bn/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_86740]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 20\u001b[0m\n\u001b[0;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     13\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mINITIAL_LR),\n\u001b[0;32m     14\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     15\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m# PERBAIKAN: Hanya gunakan 'accuracy' di sini untuk menghindari error serialisasi\u001b[39;00m\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m callbacks, _ \u001b[38;5;241m=\u001b[39m get_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwaste_model_initial_head\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINITIAL_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\waste-classifier\\server\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential_2/efficientnetb4/block4e_expand_bn/FusedBatchNormV3' defined at (most recent call last):\n    File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n      app.launch_new_instance()\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n      app.start()\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n      self.io_loop.start()\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"C:\\Users\\asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 397, in dispatch_shell\n      await result\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 368, in execute_request\n      await super().execute_request(stream, ident, parent)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 752, in execute_request\n      reply_content = await reply_content\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 455, in do_execute\n      res = shell.run_cell(\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 577, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3048, in run_cell\n      result = self._run_cell(\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3103, in _run_cell\n      result = runner(coro)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3308, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3490, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3550, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_20580\\1583126195.py\", line 20, in <module>\n      history = model.fit(\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\sequential.py\", line 410, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 850, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 660, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 108, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"d:\\waste-classifier\\server\\venv\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 634, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'sequential_2/efficientnetb4/block4e_expand_bn/FusedBatchNormV3'\nOOM when allocating tensor with shape[32,672,14,14] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential_2/efficientnetb4/block4e_expand_bn/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_86740]"
     ]
    }
   ],
   "source": [
    "def get_callbacks(model_name):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    model_path = os.path.join(config.SAVE_DIR, f\"{model_name}_{timestamp}.h5\")\n",
    "    \n",
    "    return [\n",
    "        keras.callbacks.ModelCheckpoint(filepath=model_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, verbose=1)\n",
    "    ], model_path\n",
    "\n",
    "print(\"\\n--- TAHAP 1: Melatih Head Model (Feature Extraction) ---\")\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=config.INITIAL_LR),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'] # PERBAIKAN: Hanya gunakan 'accuracy' di sini untuk menghindari error serialisasi\n",
    ")\n",
    "\n",
    "callbacks, _ = get_callbacks(\"waste_model_initial_head\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=config.INITIAL_EPOCHS,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c06b11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- TAHAP 2: Melatih Sebagian Layer (Fine-Tuning) ---\")\n",
    "base_model = model.layers[0]\n",
    "base_model.trainable = True\n",
    "\n",
    "fine_tune_at = 100\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=config.INITIAL_LR / 10),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'] # PERBAIKAN: Hanya gunakan 'accuracy' di sini\n",
    ")\n",
    "\n",
    "callbacks_finetune, best_model_path = get_callbacks(\"high_accuracy_waste_classifier\")\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_gen,\n",
    "    epochs=config.INITIAL_EPOCHS + config.FINE_TUNE_EPOCHS,\n",
    "    initial_epoch=history.epoch[-1],\n",
    "    validation_data=val_gen,\n",
    "    callbacks=callbacks_finetune\n",
    ")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Training Selesai!\")\n",
    "print(f\"ðŸ’¾ Model terbaik disimpan di: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82aa2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Memulai Evaluasi Akhir pada Model Terbaik ---\")\n",
    "best_model = keras.models.load_model(best_model_path)\n",
    "\n",
    "val_gen.reset()\n",
    "predictions = best_model.predict(val_gen, verbose=1)\n",
    "predicted_classes = (predictions > 0.5).astype(int).flatten()\n",
    "true_classes = val_gen.classes\n",
    "class_names = list(val_gen.class_indices.keys())\n",
    "\n",
    "print(\"\\nðŸ“Š Laporan Klasifikasi:\\n\" + \"-\"*40)\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_names, digits=4))\n",
    "\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Label Sebenarnya')\n",
    "plt.xlabel('Label Prediksi')\n",
    "plt.savefig(os.path.join(config.SAVE_DIR, 'confusion_matrix.png'))\n",
    "plt.show()\n",
    "\n",
    "# Plotting training history\n",
    "all_history = {\n",
    "    'accuracy': history.history['accuracy'] + history_fine.history['accuracy'],\n",
    "    'val_accuracy': history.history['val_accuracy'] + history_fine.history['val_accuracy'],\n",
    "    'loss': history.history['loss'] + history_fine.history['loss'],\n",
    "    'val_loss': history.history['val_loss'] + history_fine.history['val_loss'],\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(all_history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(all_history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(all_history['loss'], label='Training Loss')\n",
    "plt.plot(all_history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(config.SAVE_DIR, 'training_history.png'))\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
